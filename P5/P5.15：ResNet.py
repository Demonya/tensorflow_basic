#   ResNet:提出了层间残差跳连,引入了前方信息,缓解梯度消失,使神经网络增加层数成为可能。
#   单纯堆叠神经网络层数,会使神经网络模型退化,以至于后面的特征丢失了前面特征的原本模样
#   用一根跳连线将前面的特征直接接到后边,使输出结果包含了堆叠卷积的非线性输出和跳过两层堆叠卷积直接连接过来的恒等映射x,
#   让它们对应的元素相加,有效缓解了神经网络模型堆叠导致的退化,使得神经网络可以向着更深层级发展。
#   ResNet中的“+” 与InceptionNet中的“+” 不同的。
#   Inception中的“+”是沿深度方向叠加,相当于千层蛋糕增加层数
#   ResNet块中的“+”是两路特征图对应元素相加,相当于两个矩阵对应元素做加法
#   ResNet块中有两种情况：
#   1）用实线表示：两层堆叠卷积不改变特征图的维度,也就是特征图的个数高、宽、深度都相同,可以直接相加。
#   2）用虚线表示：两层堆叠卷积改变了特征图的维度,需要借助1*1的卷积来调整x的维度,是w_{x}与F_{x}的维度一致。


